{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN classifier\n",
    "The k Nearest Neighbour classifier is the easiest classifier which requires no training at all. When a test data point comes in, the Euclidean distances between this data point and all data points in the training set will be calculated and the majority class of the training points with top K smallest distances will be the class label of this test point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data set\n",
    "A girl called Helen want to build a classifier to tell if she would like to date a man(WTF?) based on three features:\n",
    "\n",
    "1. frequent flier miles earned for each year\n",
    "2. percentage of time spent on playing video games\n",
    "3. liters of ice cream cosumed for each year\n",
    "\n",
    "1 means do not want to date him at all, 2 means a little, 3 means want to date him very much.\n",
    "\n",
    "She has a data set which contains these three features for 1000 men(WOW). Let's build a kNN classifier. First let's load the data set. It is stored as a raw text in GitCafe. The loaded data is stored as pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fre_flier_miles_earned_per_year</th>\n",
       "      <th>per_of_time_spent_playing_video_games</th>\n",
       "      <th>liters_of_ice_cream_consumed_per_year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40920</td>\n",
       "      <td>8.326976</td>\n",
       "      <td>0.953952</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14488</td>\n",
       "      <td>7.153469</td>\n",
       "      <td>1.673904</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26052</td>\n",
       "      <td>1.441871</td>\n",
       "      <td>0.805124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fre_flier_miles_earned_per_year  per_of_time_spent_playing_video_games  \\\n",
       "0                            40920                               8.326976   \n",
       "1                            14488                               7.153469   \n",
       "2                            26052                               1.441871   \n",
       "\n",
       "   liters_of_ice_cream_consumed_per_year  label  \n",
       "0                               0.953952      3  \n",
       "1                               1.673904      2  \n",
       "2                               0.805124      1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy  import *\n",
    "url=\"https://coding.net/u/HongHuangNeu/p/Machine-Learning-Notes-Data/git/raw/master/DatingData/datingTestSet2.txt\"\n",
    "df=pd.read_csv(url,sep='\\t')\n",
    "df[:3] #show the first 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with this the data set. In the following we convert the lables as indexes of the data points in pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fre_flier_miles_earned_per_year</th>\n",
       "      <th>per_of_time_spent_playing_video_games</th>\n",
       "      <th>liters_of_ice_cream_consumed_per_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40920</td>\n",
       "      <td>8.326976</td>\n",
       "      <td>0.953952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14488</td>\n",
       "      <td>7.153469</td>\n",
       "      <td>1.673904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26052</td>\n",
       "      <td>1.441871</td>\n",
       "      <td>0.805124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fre_flier_miles_earned_per_year  per_of_time_spent_playing_video_games  \\\n",
       "label                                                                           \n",
       "3                                40920                               8.326976   \n",
       "2                                14488                               7.153469   \n",
       "1                                26052                               1.441871   \n",
       "\n",
       "       liters_of_ice_cream_consumed_per_year  \n",
       "label                                         \n",
       "3                                   0.953952  \n",
       "2                                   1.673904  \n",
       "1                                   0.805124  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_df = df.set_index(['label'])\n",
    "indexed_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data set\n",
    "In the following cell I do a scatter plot on two dimensions: 'liters_of_ice_cream_consumed_per_year' and 'per_of_time_spent_playing_video_games'. It takes a long time to render this scatter plot, so they are commented out for now. Intersted readers can download this ipython notebook, uncomment these statements and see the visualization yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cmap = {1.0: 'red', 2.0: 'blue', 3.0: 'yellow'}\n",
    "\n",
    "#df.plot(x='liters_of_ice_cream_consumed_per_year', y='per_of_time_spent_playing_video_games', kind='scatter', c=[cmap.get(c, 'black') for c in df.label])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the features and lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix=df.values #the numpy array of the pandas data frame\n",
    "labels=matrix[:,3]   #the 3rd column is the label column\n",
    "features=matrix[:,0:3] #the 0th to 2nd column is the feature columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classification function\n",
    "Define a classifier function according to the principles of kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(x,trainingSet,labels,k):\n",
    "    numberOfRows=trainingSet.shape[0];\n",
    "    # repeat x for numberOfRows times \n",
    "    xs=tile(x,(numberOfRows,1))\n",
    "    #calculate the difference of coordinates for each dimension\n",
    "    diff=trainingSet-xs\n",
    "    #calculate the square of the differences\n",
    "    square=diff*diff\n",
    "    #calculate distances\n",
    "    distances=(square.sum(axis=1))**0.5\n",
    "    \n",
    "    #sort the distances\n",
    "    sortedIndexes=distances.argsort()\n",
    "    #calculate the frequencies of classes in top k\n",
    "    classCount={}\n",
    "    for i in range(k):\n",
    "        label=labels[sortedIndexes[i]]\n",
    "        if label in classCount:\n",
    "            classCount[label]=classCount[label]+1\n",
    "        else:\n",
    "            classCount[label]=1\n",
    "    #sort the resulted map by value\n",
    "    sortedClassLabels=sorted(classCount.items(),key=lambda x: x[1],reverse=True)\n",
    "    return sortedClassLabels[0][0]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with this classifier first. Here we use 3-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#play with this classifier first\n",
    "x=array([1,2,3]) #vector to classify\n",
    "classify(x,features,labels,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "kNN classifier is very sensitive to scaling, features with large values have large influence on the outcome, so we need to scale the features. Here we can use the following formula to scale the features to [0,1]:\n",
    "$$newValue=\\frac{oldValue-minValue}{maxValue-minValue}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function process training set\n",
    "def norm(dataSet):\n",
    "    #min value of each feature\n",
    "    minValue=dataSet.min(axis=0)\n",
    "    \n",
    "    #max value of each feature\n",
    "    maxValue=dataSet.max(axis=0)\n",
    "    \n",
    "    numberOfRows=dataSet.shape[0]\n",
    "    minValues=tile(minValue,(numberOfRows,1))\n",
    "    maxValues=tile(maxValue,(numberOfRows,1))\n",
    "    diff=maxValues-minValues\n",
    "    \n",
    "    #we need a new data set, instead of changing the stuffs in place\n",
    "    normedDataSet=zeros(shape(dataSet))\n",
    "    \n",
    "    #apply the formula\n",
    "    normedDataSet=(dataSet-minValues)/diff\n",
    "    return normedDataSet,minValue,maxValue\n",
    "\n",
    "#this function process the data point to classify\n",
    "#it takes the min values and max values calculated from the training set\n",
    "def getValue(testPoint,minValue,maxValue):\n",
    "    normedTestSet=zeros(shape(testPoint))\n",
    "    diff=maxValue-minValue\n",
    "    normedTestPoint=(testPoint-minValue)/diff\n",
    "    return normedTestPoint\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call this norm function to normalize the data point and do the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normedTrainSet,minValue,maxValue=norm(features)\n",
    "newX=getValue(x,minValue,maxValue)\n",
    "classify(newX,normedTrainSet,labels,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the classifier\n",
    "Use part of the data set as test set, use the rest as training data set to train the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testClassifier(ratio,dataSet,labels,k):\n",
    "    normalizedDataSet,minValue,maxValue=norm(dataSet)\n",
    "    numberOfRows=dataSet.shape[0]\n",
    "    numberOfTestPoints=int(numberOfRows*ratio)\n",
    "    totalCount=0\n",
    "    errorCount=0\n",
    "    for i in range(numberOfTestPoints):\n",
    "        #the ith test point\n",
    "        x=normalizedDataSet[i]\n",
    "        #apply the classifier\n",
    "        label=classify(x,normalizedDataSet[numberOfTestPoints:numberOfRows],labels[numberOfTestPoints:numberOfRows],k)\n",
    "        totalCount=totalCount+1\n",
    "        if(label!=labels[i]):\n",
    "            errorCount=errorCount+1\n",
    "        \n",
    "    errorRate=errorCount/totalCount\n",
    "    return errorRate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use to 10% of the data points as test data set to test the 3-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testClassifier(0.1,features,labels,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
